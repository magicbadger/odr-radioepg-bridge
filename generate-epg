#!/usr/bin/env python

"""
ODR-Bridge-EPG

Feed in a multiplex configuration file and an output bitstream path.

The mux config will be scanned for services linked to an EPG packet data channel. The service SI files will
be resolved and demarshalled.

These will then be combined to a multiplex SI file. This is then used to pull back logo files for each service in the 3 
lowest sizes. Also 2 days PI files. All these are then encoded to an MOT directory bitstream.

"""

import argparse
import os, sys
from datetime import datetime, timedelta
import urllib2
import logging
from json import dumps, JSONEncoder
import random
import string
import re
import logging

from spi import DabBearer, IpBearer, Time, ServiceInfo, Multimedia, ShortName, xml, binary

from mot import MotObject, ContentType, SortedHeaderInformation
from mot.epg import EpgContentType, ScopeId, ScopeStart, ScopeEnd

from msc.datagroups import encode_directorymode
from msc.packets import encode_packets


def filter_by_bearer(service):
    bearers = [x for x in service.bearers if isinstance(x, (DabBearer))] # can include IP bearers if you like
    return service

def get_services_for_bearers(bearers, url):
    logger.debug('getting services for bearers from %s : %s', url, bearers)
    response = urllib2.urlopen(url)
    unmarshalled = xml.unmarshall(response.read())
    services = filter(lambda s : len(filter(lambda b : b in bearers, s.bearers)) > 0, unmarshalled.services)
    logger.debug('number of services found %d', len(services))
    if len(services) == 0:
        raise Error('no services found for bearers %s from url %s' % (bearers, url))
    return services

def get_filename():
    return ''.join(random.choice(string.ascii_lowercase) for i in range(6))

def encode_image(url):
    logger.debug('encoding image from %s', url)
    response = urllib2.urlopen(url)
    data = response.read()
    logger.debug('read %d bytes of image data', len(data))
    if len(data) > 16000:
        logger.debug('WARN: image size is excessive (greater than 16kBytes)')
    return data

parser = argparse.ArgumentParser(description='Encodes an SPI bitstream for services in a multiplex configuration file')
parser.add_argument('f',  nargs=1, help='multiplex configuration file')
parser.add_argument('-o', dest='output', help='output bitstream file')
parser.add_argument('-X', dest='debug', action='store_true', help='turn debug on')
parser.add_argument('-d', dest='days', type=int, default=2, help='number of days ahead to encode schedule files')
parser.add_argument('-p', dest='packet_size', type=int, default=96, help='Packet size in bytes')
parser.add_argument('-a', dest='packet_address', type=int, default=1, help='Packet address')
parser.add_argument('-D', dest='datagroup_output', action='store_true', help='output Datagroups instead of Packets')
args = parser.parse_args()

if args.debug:
    logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger('odr.bridge.epg')
logging.getLogger('spi.binary').setLevel(logging.INFO)

# read in the mux config
c = open(args.f[0]).read()

def calculate_scope(schedule): # this should probably be in the main codebase
    start, end = schedule.scope
    if start is not None and end is not None: return (start, end)
    if start is None:
        for programme in schedule.programmes:
            for location in programme.locations:
                for time in location.times:
                    if not isinstance(time, Time): continue
                    if start is None or time.actual_time < start: start = time.actual_time
                    if end is None or (time.actual_time + time.actual_duration) > end: end = (time.actual_time + time.actual_duration)
    return (start, end)



class Generator:

    def __init__(self, days, output, packet_size, packet_address, datagroup_output):
        self.days = days if days else 0
        self.output = output if output else 'output.dat'
        self.packet_size = packet_size
        self.packet_address = packet_address
        self.datagroup_output = datagroup_output

        if self.datagroup_output:
            logger.debug('creating bitstream generator: days=%d, using datagroups', days)       
        else:
            logger.debug('creating bitstream generator: days=%d, using packets: packet_size=%d, packet_address=%d', days, packet_size, packet_address)

    def generate_epg(self, responses):

        # lets provision a list of the files and encoders that we'll use to assemble the directory 
        # list of tuples: (filename, params, function, args, kwargs)
        objects = []

        # our list of services
        all_services = []

        logger.debug('responses: %s', responses)
        
        if len(responses) == 0:
            logger.debug('No services found to encode, aborting')
            return 

        for response in responses:
            fqdn = response['fqdn']
            bearers = response['bearers']
            servers = response['servers']

            # lets take a snapshot of ensemble ECC and EId right now, but should really take this from the mux config
            ecc = bearers[0].ecc
            eid = bearers[0].eid

            # sort servers in priority (lowest), weighting highest
            servers = sorted(servers, key=lambda x: (-x['priority'], x['weight']))

            # acquire an SI file, starting with the lower priority
            for server in servers:
                domain = server['target'][:-1]
                url = 'http://%s/radiodns/spi/3.1/SI.xml' % domain 
                logger.debug('getting SI document from %s', url)
                try:
                    services = get_services_for_bearers(bearers, url)
                except: continue # move onto the next SRV record
                all_services.extend(services)

                # encode service logos and prepare the SI file
                logger.debug('encoding service logos')
                for service in services:

		    logger.debug('==== Now working on Station %s =====', service)

		    service.genres = filter(None, service.genres)                                

		    if len(service.genres) == 0:
			logger.debug('No genres are correctly defined for this station')

                    logger.debug('encoding service logo for: %s', service)

		    new_media = [] 
                    for media in filter(lambda m: 
                        m.type in (Multimedia.LOGO_COLOUR_SQUARE, Multimedia.LOGO_COLOUR_RECTANGLE) or
                        (m.content in ('image/png') and (m.width, m.height) in ((32, 32), (112, 32), (128, 128), (320, 240))), 
                        service.media):

			if media.type == Multimedia.LOGO_COLOUR_SQUARE :
                             media.content = "image/png"
                             media.width = 32
                             media.height = 32
                        elif media.type == Multimedia.LOGO_COLOUR_RECTANGLE :
			     media.content = "image/png"
                             media.width = 112
                             media.height = 32 

			logger.debug('Width %d and height %d', media.width, media.height)

			# create a sensible contentname
                        logger.debug('Media content type is %s', media.content)
			name = "{service}_{width}_{height}.{extension}".format(
				service=service.get_name(ShortName.max_length).text.replace(" ", "_"),
				width=media.width,
				height=media.height,
				extension=media.content[media.content.find("/") + 1:])
			logger.debug('creating MOT image %s from url: %s', name, media.url)
                        
                        # create MOT Object
                        o = MotObject(name, encode_image(media.url), ContentType.IMAGE_PNG if media.content == 'image/png' or media.type in (Multimedia.LOGO_COLOUR_SQUARE, Multimedia.LOGO_COLOUR_RECTANGLE) else ContentType.IMAGE_JFIF)
                        objects.append(o)

			# set the name
			media.url = name

			# set the type
			if (media.width, media.height) == (32, 32):
			    media.type = Multimedia.LOGO_COLOUR_SQUARE
			elif (media.width, media.height) == (112, 32):
			    media.type = Multimedia.LOGO_COLOUR_RECTANGLE
			else:
			    media.type = Multimedia.LOGO_UNRESTRICTED 

			new_media.append(media)

		    service.media = new_media
     
                    # get the relevant bearer for this mux
                    bearer = filter(lambda x: isinstance(x, DabBearer) and x.ecc == ecc and x.eid == eid, service.bearers)[0]

                    # now find PI files
                    if self.days > 0:
                        now = datetime.today()
                        for i in range(0, self.days):
                            day = now + timedelta(days=i)
                            pi_url = 'http://%s/radiodns/spi/3.1/dab/%03x/%04x/%04x/%01x/%s' % (domain, ((bearer.eid >> 4 & 0xf00) + bearer.ecc), bearer.eid, bearer.sid, bearer.scids, day.strftime("%Y%m%d_PI.xml"))
                            try:
                                day = now + timedelta(days=i)
                                filename = '%s_%02x.%04x.%04x.%01x_PI.xml' % (day.strftime("%Y%m%d"), bearer.ecc, bearer.eid, bearer.sid, bearer.scids)
                                # Uncomment this next line if you want to use legacy filenames
				# filename = 'w%sd%04xc0.EHA' % (day.strftime("%Y%m%d"), bearer.sid)
                                logger.debug('making request for PI file to: %s to write out as: %s', pi_url, filename)
                                f = urllib2.urlopen(pi_url)
                                data = f.read()
                                logger.debug('read %d bytes', len(data))
                                programme_info = xml.unmarshall(data)
                                
                                # get the right scope - not entirely clear from the specification how multiple schedules should be handled
                                # in terms of scope signalling
                                scope_start = None
                                scope_end = None
                                try:
                                    for schedule in programme_info.schedules:
                                        start, end = schedule.scope
                                        if scope_start == None or start < scope_start: scope_start = start
                                        if scope_end == None or end > scope_end: scope_start = start
                                        start, end = calculate_scope(schedule)
                                        if scope_start == None or start < scope_start: scope_start = start
                                        if scope_end == None or end > scope_end: scope_end = end

                                    o = MotObject(filename, binary.marshall(programme_info), EpgContentType.PROGRAMME_INFORMATION)
                                    o.add_parameter(ScopeId(bearer.ecc, bearer.eid, sid=bearer.sid, scids=bearer.scids)) 
                                    o.add_parameter(ScopeStart(scope_start))
                                    o.add_parameter(ScopeEnd(scope_end))
                                    objects.append(o)
                                except AttributeError:
                                    logger.exception('PI file at: %s is malformed', pi_url)

                            except urllib2.HTTPError as err:
                                if err.code == 404:
                                    logger.warning('could not find PI file at: %s', pi_url)
                                else:
                                    logger.exception('error finding PI file at: %s', pi_url)

                     
        # prepare the SI file
    	filename = '%s_%02x.%04x_SI.xml' % (now.strftime("%Y%m%d"),ecc,eid)
        # Uncomment this next line if you want to use legacy filenames
	# filename = 'e%02x%04xw%s.EIA' % (ecc, eid, now.strftime("%Y%m%d"))
        service_info = ServiceInfo()
        logger.debug('preparing the SI file with %d services to write out as %s', len(all_services), filename)
        for service in all_services:

            # filter out non DAB/IP bearers
            # service.bearers = filter(lambda x: isinstance(x, (DabBearer, IpBearer)), service.bearers)
            # service_info.services.append(service)  

            # filter out non DAB bearers
            service.bearers = filter(lambda x: isinstance(x, (DabBearer)), service.bearers)
            service_info.services.append(service)  

        # add the SI file 
        o = MotObject(filename, binary.marshall(service_info, ensemble=binary.Ensemble(ecc, eid)), EpgContentType.SERVICE_INFORMATION)
        o.add_parameter(ScopeId(ecc, eid))
        objects.append(o)

        logger.debug('loaded into %d MOT objects', len(objects))

        # encode to datagroups
        datagroups = encode_directorymode(objects, directory_parameters=[SortedHeaderInformation()])
        # datagroups = encode_directorymode(objects, directory_parameters=[])
        logger.debug('encoded to %d datagroups', len(datagroups))
        
        # open the output file
        if self.datagroup_output:
            logger.debug('encoded to %d datagroups', len(datagroups))
            w = open(self.output, 'wb')
        
            for datagroup in datagroups:
                w.write(datagroup.tobytes())

        else:
            packets = encode_packets(datagroups, address=self.packet_address, size=self.packet_size)
            logger.debug('encoded to %d packets', len(packets))

            # open the output file
            w = open(self.output, 'wb')

            for packet in packets:
                w.write(packet.tobytes())

# get the services and applications that the mux config suggests and construct a new virtual SI file
from odr.radiodns.resolver import resolve_epg
generator = Generator(days=args.days, output=args.output, packet_size=args.packet_size, packet_address=args.packet_address, datagroup_output=args.datagroup_output)
resolved = resolve_epg(args.f[0], generator.generate_epg)
